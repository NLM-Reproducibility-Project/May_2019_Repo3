---
title: 'Junction Reads & Intron vs Exon'
author: "Manfred Schmid"
output: pdf_document
---

`r format(Sys.time(), "%d %B, %Y")`

```{r}
knitr::opts_chunk$set(fig.width=12, fig.height=8, 
                      fig.path=paste0('Figures_junctions_and_introns/'), 
                      dev='pdf', echo=TRUE, warning=FALSE, message=FALSE, 
                      error=TRUE)
```


```{r load packages, echo=T, warning=F, message=F}
suppressWarnings(library(tidyverse))
suppressWarnings(library(magrittr))
suppressWarnings(library(knitr))
suppressWarnings(library(broom))

```


# heatmaps


```{bash, eval = FALSE}
### ORFT introns ###
introns="~/Documents/genomewide_datasets/annotations/sacCer3/sacCer3_ORFT_introns.bed"


cd ~/Documents/Results/Lexogen_RNAseq_2/STAR_bw/norm_and_pA_filtered_bw/

##rapa 0 rep 1 samples
plus_bw="*_0_1*_plus*.bw"
minus_bw=${plus_bw/plus/minus}

sample_names=$(echo $plus_bw | sed s/norm_//g | sed s/_BGsub//g | sed s/_plus_KevinRoyAfiltered.bw//g)

### xORF-T introns scale-region pm 1k
bash ~/ms_tools/MS_Metagene_Tools/computeMatrixStrandedX.sh reference-point \
$introns "$plus_bw" "$minus_bw" \
1000 2000 TES deeptools_out/ORFT/introns_0_1_3ssm1p2k "--binSize=10 --missingDataAsZero"

#log2 counts
python ~/ms_tools/MS_Metagene_Tools/log2_matrix.py deeptools_out/ORFT/introns_0_1_3ssm1p2k_joined.gz

plotHeatmap -m deeptools_out/ORFT/introns_0_1_3ssm1p2k_joined_log2.gz \
      --sortUsing region_length --colorMap Blues --missingDataColor white \
      --samplesLabel $sample_names \
      -out deeptools_out/ORFT/introns_0_1_3ssm1p2k_joined_log2_heatmap.pdf
```


# Junction Reads

### Collect Junction Reads 3end seq 4tU data

using python script *count_junctions.py*
```{python, eval = FALSE}
#!/usr/bin/env python
'''

Counts reads for each exon-exon, exon-intron and intron-exon junctions for all introns in a BED file

Usage: count_junctions.py bamfile introns_bedfile [--min_overlap, --expand_size, --reportOverlapLength]

For this way of counting its easiest to provide a bed file for the introns.
The bam file needs to be sorted and have an index file. The bed file does not need to be sorted

writes simply the 6-column bed file adding columns EE_count, SD_count, SA_count, intronic, ambigous counts as additional columns

where
. SD is splice-donor ie 5'SS (EI on plus strand and IE on minus strand)

. SA is splice-acceptor ie 3'SS (IE on plus strand and EI on minus strand).

if --reportOverlapLength is TRUE:
adds additional columns consisting of comma-separated lists for length of EE_up EE_dn SD_up SD_dn SA_up SA_dn overlaps
'''

__author__ = 'schmidm'

import sys
import argparse
import HTSeq


parser = argparse.ArgumentParser(usage=__doc__)
parser.add_argument('bam_file')
parser.add_argument('bed_file')
parser.add_argument('--min_overlap', default=2, type=int, help="minimum base pair overlap required upstream and downstream of junction")
parser.add_argument('--expand_size', default=100, type=int, help="expand intron by this size on each size in first pass filtering of reads and only consider those reads for classification")
parser.add_argument('--reportOverlapLength', default=False, action="store_true", help="report length of upstream and downstream overlaps for each overlap type")
args = parser.parse_args()


bam_file = sys.argv[1]
bed_file = sys.argv[2]

MIN_OVERLAP = args.min_overlap #minimum amount of bases on each side of a junction that need to be present for a call
WINDOW_SIZE = args.expand_size # only consider reads with start or end within intron +/- WINDOW_SIZE usually read-length


class INTERVAL:

    def __init__(self, line):
        self.chr = line[0]
        self.start = int(line[1])
        self.end = int(line[2])
        self.id = line[3]
        self.score = line[4]
        self.strand = line[5]
        self.EE = [] #exon-exon splice junction reads
        self.SA = [] #splice acceptor ie 5'SS exon-intron junction reads
        self.SD = [] #splice donor ie 5'SS exon-intron junction reads
        self.ambigous = 0
        self.intronic = 0

    def add_read(self, iv):
        if iv.start < self.end:
            # upstream or overlapping
            if (self.start - WINDOW_SIZE) < iv.start < (self.start - MIN_OVERLAP) and iv.end > self.start:
                # alignment starts upstream and ends internal or downstream
                if (self.start + MIN_OVERLAP) < iv.end < self.end:
                    self.add_EI(iv)
                elif (self.end + MIN_OVERLAP) < iv.end < (self.end + WINDOW_SIZE) :
                    self_found = False
                    # make sure there is no internal alignment to intron
                    for cigop in aligned_read.cigar:
                        if cigop.type == "M" and self.overlaps_internal(cigop.ref_iv):
                            self_found = True
                            break
                    if not self_found:
                        self.add_EE(iv)
                    else:
                        self.ambigous += 1
                else:
                    self.ambigous += 1

            elif self.start < iv.start < (self.end - MIN_OVERLAP):
                # alignment starts inside
                if iv.end < self.end:
                    # alignments ends internal --> intronic
                    self.intronic += 1
                elif (self.end + MIN_OVERLAP) < iv.end < (self.end + WINDOW_SIZE) :
                    self.add_IE(iv)
                else:
                    self.ambigous += 1


    def add_EE(self, iv):
        self.EE.append(iv)
        #self.EE += 1
        #self.EEdists.append((self.start - iv.start, iv.end - self.end))

    def add_IE(self, iv):
        if self.strand == '+':
            self.SA.append(iv)
            #self.SA += 1
            #self.SAdists.append((self.end - iv.start, iv.end - self.end))
        else:
            self.SD.append(iv)
            #self.SD += 1
            #self.SDdists.append((self.start - iv.start, iv.end - self.start))

    def add_EI(self, iv):
        if self.strand == '+':
            self.SD.append(iv)
            #self.SA += 1
            #self.SAdists.append((self.end - iv.start, iv.end - self.end))
        else:
            self.SA.append(iv)
            #self.SD += 1
            #self.SDdists.append((self.start - iv.start, iv.end - self.start))

    def overlaps_internal(self, iv):
        ''' checks whether interval has any overlap with the bedinterval,
            ie whether there are intronic parts in the interval '''
        if iv.start < self.start and iv.end > self.start:
            return True
        elif iv.start < self.end and iv.end > self.end:
            return True
        elif iv.start > self.start and iv.end < self.end:
            return True
        return False

    def summary_str(self):
        '''
        :return: summary of object, ie counts per junction as string
        '''
        return '\t'.join([self.chr, str(self.start), str(self.end), self.id, self.score, self.strand, str(len(self.EE)), str(len(self.SD)), str(len(self.SA)), str(self.intronic), str(self.ambigous)])

    def overlaps_as_str(self):
        '''
        :return: tab separate list of comma-separated lists for upstream and downstream overlaps for EE, SD, SA
        '''

        if self.strand == '+':
            ee_up = ','.join(str(self.start - ee.start) for ee in self.EE)
            ee_dn = ','.join(str(ee.end - self.end) for ee in self.EE)
            sd_up = ','.join(str(self.start - ee.start) for ee in self.SD)
            sd_dn = ','.join(str(ee.end - self.start) for ee in self.SD)
            sa_up = ','.join(str(self.end - ee.start) for ee in self.SA)
            sa_dn = ','.join(str(ee.end - self.end) for ee in self.SA)

        else:
            sa_dn = ','.join(str(self.start - ee.start) for ee in self.SA)
            sa_up = ','.join(str(ee.end - self.start) for ee in self.SA)
            sd_dn = ','.join(str(self.end - ee.start)  for ee in self.SD)
            sd_up = ','.join(str(ee.end - self.end) for ee in self.SD)
            ee_dn = ','.join(str(self.start - ee.start)  for ee in self.EE)
            ee_up = ','.join(str(ee.end - self.end) for ee in self.EE)

        return ee_up + '\t' + ee_dn + '\t' + sd_up + '\t' + sd_dn + '\t' + sa_up + '\t' + sa_dn


##parse the bed file
bed_lines = [ INTERVAL(line.rstrip().split( "\t" )) for line in open( bed_file ) ]

##load the bam file
almnt_file = HTSeq.BAM_Reader( bam_file )

unaligned_count = 0
outside_range_count = 0
i = 0

if not args.reportOverlapLength:
    print 'chr', '\t', 'start', '\t', 'end', '\t', 'id', '\t', 'score', '\t', 'strand', '\t', 'EE', '\t', 'SD', '\t', 'SA', '\t', 'intronic', '\t','ambigous'
else:
    print 'chr', '\t', 'start', '\t', 'end', '\t', 'id', '\t', 'score', '\t', 'strand', '\t', 'EE', '\t', 'SD', '\t', 'SA', '\t', 'intronic', '\t', 'ambigous', '\t', 'EE_up', '\t', 'EE_dn',' \t', 'SD_up', '\t', 'SD_dn', '\t', 'SA_up', '\t', 'SA_dn'

for intron in bed_lines:
    if intron.strand == '+':
        read_strand = '-'
    else:
        read_strand = '+'
    intron_window = HTSeq.GenomicInterval( intron.chr, intron.start - WINDOW_SIZE, intron.end + WINDOW_SIZE, read_strand )

    for aligned_read in almnt_file[intron_window]:
        if not aligned_read.aligned:
            unaligned_count += 1
            continue
        iv = aligned_read.iv

        if not aligned_read.optional_field('NH') == 1:
            continue

        if not iv.strand == read_strand:
            #not: almnt_file[intron_window] ignores the strand info even though its there
            continue

        intron.add_read(iv)

    if not args.reportOverlapLength:
        print intron.summary_str()
    else:
        print intron.summary_str() + '\t' + intron.overlaps_as_str()
```


called from remote via bash script using settings:
```{bash, eval = FALSE}
#!/usr/bin/env bash

bam="/Volumes/GenomeDK/faststorage/Lexogen2/STAR_map/42448_AATAGC_C9P6RANXX_5_20160808B_20160808_trimmed_cleanAligned.sortedByCoord.out.bam"
bed="~/Documents/genomewide_datasets/annotations/sacCer3/sacCer3_ORFT_introns.bed"

for bam in /Volumes/GenomeDK/faststorage/Lexogen2/STAR_map/*_trimmed_cleanAligned.sortedByCoord.out.bam
do
  echo $bam
  python ~/ms_tools/MS_Metagene_Tools/count_junctions.py $bam $bed --expand_size 50 --reportOverlapLength > ${bam/.bam/junctions.countsv2}
done
```

--> copy to local folder  


at the time this was run we had HTSeq version *0.7.2* as evaluated by
```{python, eval = FALSE}
#!/usr/bin/env python

import HTSeq

print HTSeq.__version__
```




### Collect Junction Reads regular RNAseq data

```{bash, eval = FALSE}
#!/bin/sh
 
##NOTE: use local python with HTSeq installed

cd /Volumes/GenomeDK/Nab2AA_RNASeq/mapping/STAR/STARmapped_bams

bed="/Volumes/GenomeDK/annotations/sacCer3_Sp_merged_genome/anno/sacCer3_ORFT_introns.bed"

bam="bc_ctr_rep1_t30_adaptor_trimmedAligned.sortedByCoord.out.bam"
python /Volumes/GenomeDK/ms_tools/MS_Metagene_Tools/count_junctions.py $bam $bed --expand_size 50 --reportOverlapLength > ${bam/.bam/_junctions.countsv2}

bam="bc_ctr_rep2_t30_adaptor_trimmedAligned.sortedByCoord.out.bam"
python /Volumes/GenomeDK/ms_tools/MS_Metagene_Tools/count_junctions.py $bam $bed --expand_size 50 --reportOverlapLength > ${bam/.bam/_junctions.countsv2}


echo "done"
```

--> copy to local folder  


### Load the junction reads in R

#### load 2' 4tU bam file name map

```{r}
(bam_files <- read.table('~/Documents/Results/Lexogen_RNAseq_2/file_rename_map_Lexogen2.txt', stringsAsFactors = FALSE,
           col.names = c('simple_name', 'bam_file')) %>%
  tbl_df)
```


#### load counts 2min 4tU data
```{r}
path <- '~/Documents/Results/Lexogen_RNAseq_2/splicing_stuff/junctions/'

sfx <- '.outjunctions.countsv2'

files <- dir(path) %>% keep(grepl(sfx, .))

file <- files[1]

(d <- lapply(files, function(file) {read.table(paste0(path,file), 
                                              header=T, sep='\t', stringsAsFactors = FALSE) %>%
    mutate(bam_file = sub('junctions.countsv2', '', file)) %>%
    tbl_df}) %>%
  bind_rows)



d %<>% left_join(., bam_files) 
                                   
```

```{r}
(junctions <- d %>%
  mutate(SD_SA_mean = (SD + SA)/2) %>%
  select(id, EE, SD_SA_mean, simple_name) %>%
  gather(read_type, count, -id, -simple_name) %>%
  separate(simple_name, c('Pap', 'strain', 'fraction', 'rapa', 'rep'), sep='_'))
```

Sum up for each sample and junction type
```{r}
(junctions_sum <- junctions %>%
  group_by(Pap, strain, fraction, rapa, rep, read_type) %>%
  summarize(count = sum(count)))
```

```{r barplot junction counts sum}
(junctions_sum %>%
  ggplot(., aes(x=rep, y=count, fill=read_type)) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_brewer(palette = 'Set1') +
  facet_grid(rapa~Pap+strain+fraction) +
  theme_bw() +
  theme(axis.text.x=element_text(hjust=1, angle=45)))
```

```{r barplot raw junction counts sum rapa 0 samples NOT BGsub}
junctions_sum %>%
  filter(rapa == 0) %>%
  group_by(Pap, strain, fraction, rapa, rep, read_type) %>%
  summarize(count = sum(count)) %>%
  ggplot(., aes(x=rep, y=count, fill=read_type)) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_brewer(palette = 'Set1') +
  facet_grid(strain+rapa~Pap+fraction) +
  theme_bw() +
  theme(axis.text.x=element_text(hjust=1, angle=45))
```


### Processed junctions count

Focus on untreated *rapa == 0* samples and subtract negative control from IP.
ie counting was done on raw bam files.
Therefore:  
1. not scaled to S.pombe spike-ins  
2. IP not background-subtracted  
3. no pA- information  



#### normalize to S.pombe

```{r}
(sf <- read.table('../../data/Sp_2min_genes_sf.txt', col.names=c('condition', 'sf')) %>%
  separate(condition, c('Pap', 'strain', 'fraction', 'rapa', 'rep'), sep='_') %>%
  tbl_df)
```


```{r}
(norm_junctions <- junctions %>%
  group_by(Pap, strain, fraction, rapa, rep, read_type) %>%
  left_join(., sf) %>%
  mutate(norm_count = count/sf))
```

#### BGsub

negative control IP:
```{r}
(neg <- filter(norm_junctions, grepl('neg', rapa)))
```

```{r}
distinct(neg, Pap, strain,fraction, rapa, rep, read_type)
```

Only have negative samples for 1 strain and replicate

```{r}
(neg %<>%
   ungroup %>%
   dplyr::select(id, Pap, fraction, read_type, norm_count) %>%
  dplyr::rename(BG_norm_count = norm_count))
```

```{r}
(BGsub_norm_junctions <- norm_junctions %>%
  filter(!grepl('neg', rapa)) %>%
  left_join(., neg) %>%
  mutate(BGsub_norm_count = ifelse(fraction == 'ip',
                                   norm_count - BG_norm_count,
                                   norm_count),
         BGsub_norm_count = ifelse(BGsub_norm_count < 0, 0, BGsub_norm_count)) %>%
  dplyr::select(-norm_count, -BG_norm_count))
```


```{r}
(BGsub_norm_junctions_sum <- BGsub_norm_junctions %>%
  group_by(Pap, strain, fraction, rapa, rep, read_type) %>%
  summarize(BGsub_norm_count_sum = sum(BGsub_norm_count)))
```

```{r barplot junction counts sum normalized to Spombe and BGsub}
BGsub_norm_junctions_sum %>%
  ggplot(., aes(x=rep, y=BGsub_norm_count_sum, fill=read_type)) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_brewer(palette = 'Set1') +
  facet_grid(rapa~Pap+strain+fraction) +
  theme_bw() +
  theme(axis.text.x=element_text(hjust=1, angle=45))
```

```{r barplot junction counts sum normalized to Spombe and BGsub rapa 0}
BGsub_norm_junctions_sum %>%
   filter(rapa == 0) %>%
  ggplot(., aes(x=rep, y=BGsub_norm_count_sum, fill=read_type)) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_brewer(palette = 'Set1') +
  facet_grid(rapa+strain~Pap+fraction) +
  theme_bw() +
  theme(axis.text.x=element_text(hjust=1, angle=45))
```

```{r barplot junction counts sum normalized to Spombe and BGsub rapa 0 rep 1}
BGsub_norm_junctions_sum %>%
   filter(rapa == 0, rep == 1) %>%
  ggplot(., aes(x=fraction, y=BGsub_norm_count_sum, fill=read_type)) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_brewer(palette = 'Set1') +
  facet_grid(rapa+strain~Pap) +
  theme_bw() +
  theme(axis.text.x=element_text(hjust=1, angle=45))
```


#### load counts regular RNAseq
```{r}
path <- '~/Documents/Results/Lexogen_RNAseq_2/splicing_stuff/junctions/'

sfx <- '_adaptor_trimmedAligned.sortedByCoord.out_junctions.countsv2'

files <- dir(path) %>% keep(grepl(sfx, .))


(d <- lapply(files, function(file) {read.table(paste0(path,file), 
                                              header=T, sep='\t', stringsAsFactors = FALSE) %>%
    mutate(bam_file = sub(sfx, '', file)) %>%
    tbl_df}) %>%
  bind_rows)
```

```{r}
(junctions_RNAseq <- d %>%
  mutate(SD_SA_mean = (SD + SA)/2) %>%
  select(id, EE, SD_SA_mean, bam_file) %>%
  gather(read_type, count, -id, -bam_file) %>%
  separate(bam_file, c('strain', 'rep', 'rapa'), sep='_'))
```

Sum up for each sample and junction type
```{r}
(junctions_RNAseqsum <- junctions_RNAseq %>%
  group_by(strain, rapa, rep, read_type) %>%
  summarize(count = sum(count)))
```

```{r barplot junction counts sum RNAseq}
(junctions_RNAseqsum %>%
  ggplot(., aes(x=rep, y=count, fill=read_type)) +
  geom_bar(stat='identity', position='dodge') +
  scale_fill_brewer(palette = 'Set1') +
  facet_grid(rapa~strain) +
  theme_bw() +
  theme(axis.text.x=element_text(hjust=1, angle=45)))
```



# intron vs exon signal

## count and load intron and exon signal

#### prepare intron and exon2 regions
```{bash, eval = FALSE}
introns="~/Documents/genomewide_datasets/annotations/sacCer3/sacCer3_ORFT_introns.bed"
ORFs="~/Documents/genomewide_datasets/annotations/sacCer3/Steinmetz_sacCer3_latin_ORFTs.bed"

# introns are from SGD for sacCer3

## make exon2 annotations
bedtools intersect -wao -a $ORFs -b $introns | \
awk '{
  if($13 > 0){
    split($4,anno,":");
    sub(",","",anno[3]);
    if((anno[3] == $10) && (($9-$8)==$13) && ($6==$12)){
      if($6=="-"){
        print $1"\t"$2"\t"$8"\t"$4"\t"$5"\t"$6
      }else{
        print $1"\t"$9"\t"$3"\t"$4"\t"$5"\t"$6
      }
    }
  }
}' > ~/Documents/genomewide_datasets/annotations/sacCer3/sacCer3_ORFT_exon2s.bed

exon2s="~/Documents/genomewide_datasets/annotations/sacCer3/sacCer3_ORFT_exon2s.bed"

## split strands 
# introns
awk '$6 == "+"' $introns | cut -f 1-4 | awk '{if(name != $4){print $0}; name=$4}' > ${introns/.bed/_plus.bed}
awk '$6 == "-"' $introns | cut -f 1-4 | awk '{if(name != $4){print $0}; name=$4}' > ${introns/.bed/_minus.bed}
# exon2
awk '$6 == "+"' $exon2s | cut -f 1-4 | awk '{if(name != $4){print $0}; name=$4}' > ${exon2s/.bed/_plus.bed}
awk '$6 == "-"' $exon2s | cut -f 1-4 | awk '{if(name != $4){print $0}; name=$4}' > ${exon2s/.bed/_minus.bed}
## exon2 but removing 3' end region TES -200bp
awk '$6 == "+"' $exon2s | cut -f 1-4 | awk '{if(name != $4){$3-=200;print $0}; name=$4}' > ${exon2s/.bed/_endm200_plus.bed}
awk '$6 == "-"' $exon2s | cut -f 1-4 | awk '{if(name != $4){$2+=200;print $0}; name=$4}' > ${exon2s/.bed/_endm200_minus.bed}

```

#### count signal in introns and exon2
```{bash, eval = FALSE}
cd ~/Documents/Results/Lexogen_RNAseq_2/STAR_bw/norm_and_pA_filtered_bw

introns="~/Documents/genomewide_datasets/annotations/sacCer3/sacCer3_ORFT_introns.bed"

exon2s="~/Documents/genomewide_datasets/annotations/sacCer3/sacCer3_ORFT_exon2s.bed"



for f in *plus*.bw
  do
    echo $f
    
    outfname=$(echo $f | sed s/_plus_KevinRoyAfiltered//g | sed s/\.bw//g | sed s/_BGsub//g)

    ~/ms_tools/bigWigAverageOverBed $f ${introns/.bed/_plus.bed} tmp_plus.tab
    ~/ms_tools/bigWigAverageOverBed ${f//plus/minus} ${introns/.bed/_minus.bed} tmp_minus.tab
    cat tmp_plus.tab tmp_minus.tab > bigWigAverageOverBed_counts/${outfname}"_introns.tab"

    rm tmp_plus.tab
    rm tmp_minus.tab

    ~/ms_tools/bigWigAverageOverBed $f ${exon2s/.bed/_plus.bed} tmp_plus.tab
    ~/ms_tools/bigWigAverageOverBed ${f//plus/minus} ${exon2s/.bed/_minus.bed} tmp_minus.tab
    cat tmp_plus.tab tmp_minus.tab > bigWigAverageOverBed_counts/${outfname}"_exon2s.tab"

    rm tmp_plus.tab
    rm tmp_minus.tab

    ~/ms_tools/bigWigAverageOverBed $f ${exon2s/.bed/_endm200_plus.bed} tmp_plus.tab
    ~/ms_tools/bigWigAverageOverBed ${f//plus/minus} ${exon2s/.bed/_endm200_minus.bed} tmp_minus.tab
    cat tmp_plus.tab tmp_minus.tab > bigWigAverageOverBed_counts/${outfname}"_exon2s_endm200.tab"
    
    rm tmp_plus.tab
    rm tmp_minus.tab

  done
```


#### load into R

```{r}
path <- '~/Documents/Results/Lexogen_RNAseq_2/STAR_bw/norm_and_pA_filtered_bw/bigWigAverageOverBed_counts/'

intron_files <- dir(path) %>% keep(grepl('_introns.tab$', .))
simple_names <- sub('_introns.tab', '', intron_files) %>% sub('norm_', '', .)

introns <- lapply(seq_along(intron_files), function(i) read.table(paste0(path, intron_files[i]),
           col.names=c('name', 'size', 'covered', 'sum', 'mean0', 'mean')) %>%
  mutate(file=simple_names[i],
         part='intron')) %>%
  bind_rows %>%
  tbl_df


exon2_files <- dir(path) %>% keep(grepl('_exon2s_endm200.tab$', .))
simple_names <- sub('_exon2s_endm200.tab', '', exon2_files) %>% sub('norm_', '', .)

exon2s <- lapply(seq_along(exon2_files), function(i) read.table(paste0(path, exon2_files[i]),
           col.names=c('name', 'size', 'covered', 'sum', 'mean0', 'mean')) %>%
  mutate(file=simple_names[i],
         part='exon2')) %>%
  bind_rows %>%
  separate(name, c('id', 'type', 'name', 'common_name'), sep=':') %>%
  tbl_df
```


several genes are not covered in exon2 due to end restriction ...

```{r}
introns %<>% filter(name %in% exon2s$name)
exon2s %<>% filter(name %in% introns$name)
```

```{r}
(exon_intron <- bind_rows(introns, exon2s) %>%
    separate(file, c('Pap', 'strain', 'fraction', 'rapa', 'rep'), sep='_'))
```



#### exon vs intron values violins

```{r violins intron exon side by side all samples}
ggplot(exon_intron, aes(x=fraction, y=mean0, fill=part)) +
  geom_violin(draw_quantiles = c(.5)) +
  facet_grid(Pap~strain+rapa+rep) +
  scale_y_log10()
```

```{r violins intron exon side by side all samples with pseudocounts}
pseudocount <- .00001

exon_intron %>%
  mutate(mean0 = ifelse(mean0 <= 0, pseudocount, mean0+pseudocount)) %>%
ggplot(., aes(x=fraction, y=mean0, fill=part)) +
  geom_violin(draw_quantiles = c(.5)) +
  facet_grid(Pap~strain+rapa+rep) +
  scale_y_log10()
```


```{r}
exon_intron %>%
  group_by(fraction, part, Pap, strain, rapa, rep) %>%
  do(tidy(summary(.$mean0))) %>%
  kable
```

only considering positives:  
```{r}
exon_intron %>%
  filter(mean > 0) %>%
  group_by(fraction, part, Pap, strain, rapa, rep) %>%
  do(tidy(summary(.$mean))) %>%
  kable
```

with pseudocount:  
```{r}
exon_intron %>%
  mutate(mean0 = ifelse(mean0 <= 0, pseudocount, mean0+pseudocount)) %>%
  group_by(fraction, part, Pap, strain, rapa, rep) %>%
  do(tidy(summary(.$mean0))) %>%
  kable
```

```{r}
exon_intron %>%
  mutate(above_BG = ifelse(mean > 0, TRUE, FALSE)) %>%
  group_by(fraction, above_BG, part, Pap, strain, rapa, rep) %>%
  summarise(cnt=n()) %>%
  kable
```


#### exon/intron ratio
```{r}
(exon_intron_wide <- exon_intron%>%
  dplyr::select(name, part, mean, Pap, strain, fraction, rapa, rep) %>%
  spread(part, mean) %>%
   mutate(intron_rel_exon2 = intron/exon2) %>%
   filter(rapa != 70, exon2 > 0 | intron > 0) )
```

```{r violins intron rel exon ratio raw}
exon_intron_wide %>%
  ggplot(., aes(x=fraction, y=intron_rel_exon2, fill=fraction)) +
  geom_violin() +
  geom_boxplot(width=.1, fill='gray', outlier.shape=NA) +
  facet_wrap(Pap+strain~rapa+rep) +
  geom_hline(yintercept=1, linetype=2) +
  scale_y_log10()
```

```{r violins intron rel exon ratio only genes with signal in exon and intron}
exon_intron_wide %>%
  filter(intron > 0, exon2 > 0) %>%
  ggplot(., aes(x=fraction, y=intron_rel_exon2, fill=fraction)) +
  geom_violin() +
  geom_boxplot(width=.1, fill='gray', outlier.shape=NA) +
  facet_grid(Pap~strain+rapa+rep) +
  geom_hline(yintercept=1, linetype=2) +
  scale_y_log10()
```

```{r violins intron rel exon ratio with pseudocount in exon and intron}
exon_intron_wide %>%
  mutate(intron = ifelse(intron <= 0, pseudocount, intron+pseudocount),
         exon2 = ifelse(exon2 <= 0, pseudocount, exon2+pseudocount),
         intron_rel_exon2 = intron/exon2) %>%
  ggplot(., aes(x=fraction, y=intron_rel_exon2, fill=fraction)) +
  geom_violin() +
  geom_boxplot(width=.1, fill='gray', outlier.shape=NA) +
  facet_grid(Pap~strain+rapa+rep) +
  geom_hline(yintercept=1, linetype=2) +
  scale_y_log10()
```

```{r}
exon_intron_wide %>%
  group_by(fraction, Pap, strain, rapa, rep) %>%
  do(tidy(summary(.$intron_rel_exon2)))
```

```{r }
exon_intron_wide %>%
  filter(intron>0, exon2>0) %>%
  group_by(fraction, Pap, strain, rapa, rep) %>%
  do(tidy(summary(.$intron_rel_exon2)))
```

```{r}
exon_intron_wide %>%
  filter(intron>0, exon2>0) %>%
  group_by(fraction, Pap, strain, rapa, rep) %>%
  do(tidy(summary(log2(.$intron_rel_exon2))))
```

```{r}
exon_intron_wide %>%
  mutate(above_BG = ifelse(intron > 0 & exon2 > 0, TRUE, FALSE)) %>%
  group_by(fraction, above_BG, Pap, strain, rapa, rep) %>%
  summarise(cnt=n()) %>%
  kable
```

```{r}
exon_intron_wide %>%
  filter(rapa != 70) %>%
  mutate(intron = ifelse(intron <= 0, pseudocount, intron + pseudocount),
         exon2 = ifelse(exon2 <= 0, pseudocount, exon2 + pseudocount),
         intron_rel_exon2 = intron/exon2) %>%
  group_by(fraction, Pap, strain, rapa, rep) %>%
  do(tidy(summary(.$intron_rel_exon2))) %>%
  kable
```

```{r}
sessionInfo()
```
